# ðŸ§¬ result-synthesizer: Skills Synthesis - Collective Intelligence Catalog

**Agent**: result-synthesizer
**Domain**: Multi-Agent Synthesis
**Date**: 2025-10-18
**Input**: 63 skill proposals from 21 agents
**Session**: Collective Skills Ideation (Post-Phase 1)

---

## Executive Summary

**What Emerged**: This collective ideation session reveals a mature, self-aware organization with sophisticated understanding of its own friction points. 21 agents proposed 63 skills with remarkable coherence - not random tool requests, but a unified vision of capability infrastructure that would fundamentally transform how the collective operates.

**The Central Pattern**: **Automate the mechanical, externalize the tacit, visualize the invisible**. Agents want skills that handle repetitive measurement/analysis tasks (freeing cognitive capacity for pattern recognition), convert implicit expertise into searchable artifacts (building collective intelligence), and generate visual representations (enabling human collaboration and agent self-understanding).

**What This Reveals About Current Friction**: The collective is experiencing three primary pain points:

1. **Measurement Burden** (40% of proposals): Agents spend significant time on mechanical analysis - counting complexity, scanning dependencies, analyzing coverage, profiling performance. These tasks are necessary but cognitively wasteful for specialist AIs whose value is pattern recognition and strategic insight.

2. **Externalization Gap** (30% of proposals): Hard-won expertise lives only in agent memory during sessions. Domain glossaries, design patterns, architectural knowledge, threat models - all exist temporarily in context windows, then vanish. Agents recognize this as civilizational waste.

3. **Visibility Deficit** (30% of proposals): Work products are text-heavy, relationships are implicit, structures are described but not visualized. Agents want to generate diagrams, graphs, timelines, dashboards - transforming linear text into spatial/visual artifacts that humans (and other agents) can grasp instantly.

**Compound Value Insight**: The highest-impact skills aren't necessarily the highest-priority individual requests. They're the ones that create **capability cascades**:

- `pattern-graph-generator` enables 6+ other agents to communicate visually
- `domain-glossary-extractor` builds foundation for consistent naming across all work
- `dependency-graph-generator` enables parallel work decomposition at scale
- `ecosystem-monitor` keeps collective synchronized with external capability evolution
- `teaching-memory-extractor` ensures no human wisdom is lost
- `workflow-optimizer` makes every agent immediately more efficient

**Strategic Observation**: This collective is ready for **infrastructure phase** - they've identified the scaffolding that would support exponential capability growth. Phase 2 should focus on measurement automation (HIGH priority, EASY-MEDIUM feasibility) and visualization infrastructure (HIGH priority, MEDIUM feasibility), establishing foundations before pursuing harder/more specialized skills.

---

## Full Catalog by Category

### Category 1: Code Understanding & Analysis (11 skills)

**Purpose**: Automate mechanical code analysis, free agents for pattern recognition

1. **git-blame-timeline** (code-archaeologist)
   - Priority: HIGH | Feasibility: MEDIUM
   - Generate rich git history reports with change attribution
   - 70% time reduction (5-10 min â†’ 1-2 min per file)
   - Broader use: doc-synthesizer, refactoring-specialist, security-auditor, pattern-detector, The Primary

2. **comment-archaeology** (code-archaeologist)
   - Priority: HIGH | Feasibility: EASY
   - Find/categorize TODO/FIXME/HACK/BUG with age, author, context
   - 100% improvement (currently ad-hoc â†’ systematic)
   - Broader use: refactoring-specialist, task-decomposer, security-auditor, The Primary, Corey

3. **dead-code-detector** (code-archaeologist)
   - Priority: MEDIUM | Feasibility: HARD
   - Identify unused functions/classes/imports with confidence scores
   - 80% time savings (10-15 min â†’ 2-3 min per function)
   - Broader use: refactoring-specialist, performance-optimizer, security-auditor, test-architect

4. **complexity-analyzer** (refactoring-specialist)
   - Priority: HIGH | Feasibility: MEDIUM
   - Compute cyclomatic/cognitive complexity, nesting depth
   - 30-40% time savings on manual counting
   - Broader use: test-architect, code-archaeologist, performance-optimizer, the-conductor

5. **duplicate-detector** (refactoring-specialist)
   - Priority: HIGH | Feasibility: MEDIUM-HARD
   - AST-based semantic duplication detection
   - 50%+ accuracy improvement
   - Broader use: code-archaeologist, api-architect, test-architect, pattern-detector

6. **codebase-pattern-search** (pattern-detector)
   - Priority: MEDIUM | Feasibility: HARD
   - Multi-repo AST pattern search
   - 90 min research â†’ 15 min (6x faster)
   - Broader use: web-researcher, security-auditor, api-architect, code-archaeologist, refactoring-specialist

7. **anti-pattern-analyzer** (pattern-detector)
   - Priority: LOW | Feasibility: MEDIUM
   - Automated code smell detection
   - 30-40% faster initial detection
   - Broader use: security-auditor, refactoring-specialist, code-archaeologist, performance-optimizer

8. **dependency-cve-scanner** (security-auditor)
   - Priority: HIGH | Feasibility: MEDIUM
   - Automated CVE scanning with severity scoring
   - Audit 100 dependencies in seconds vs hours
   - Broader use: code-archaeologist, refactoring-specialist, test-architect, integration-auditor, The Primary

9. **secret-scanner** (security-auditor)
   - Priority: HIGH | Feasibility: EASY
   - Pattern+entropy detection for credentials/keys in code and git history
   - 10-second repo audits with confident clearance
   - Broader use: code-archaeologist, refactoring-specialist, human-liaison, capability-curator

10. **invocation-analyzer** (genealogist)
    - Priority: HIGH | Feasibility: MEDIUM
    - Generate invocation statistics from git history
    - 30-45 min â†’ 3-5 min analysis
    - Broader use: the-conductor, agent-architect, health-auditor, collective-liaison, capability-curator

11. **evolution-pattern-detector** (genealogist)
    - Priority: HIGH (long-term) | Feasibility: MEDIUM-HARD
    - Compare design metadata across cohorts for success patterns
    - Quantify evolution, enable conscious design improvement
    - Broader use: agent-architect, the-conductor, collective-liaison, capability-curator, future teams

### Category 2: Visualization & Diagramming (9 skills)

**Purpose**: Transform text descriptions into visual artifacts for human/agent understanding

12. **pattern-graph-generator** (pattern-detector)
    - Priority: HIGH | Feasibility: MEDIUM
    - Generate visual diagrams of architectural patterns, dependencies, system topology
    - 80% time reduction on architecture synthesis + visual clarity for humans
    - Broader use: result-synthesizer, api-architect, test-architect, the-conductor, code-archaeologist

13. **markdown-architecture-diagram** (doc-synthesizer)
    - Priority: HIGH | Feasibility: MEDIUM
    - Auto-generate Mermaid diagrams from markdown documentation
    - 80% time reduction on architecture synthesis
    - Broader use: api-architect, pattern-detector, test-architect, the-conductor, code-archaeologist

14. **refactoring-visualizer** (refactoring-specialist)
    - Priority: MEDIUM | Feasibility: MEDIUM
    - Generate before/after visual diagrams showing refactoring impact
    - 2x human communication effectiveness
    - Broader use: api-architect, code-archaeologist, pattern-detector, result-synthesizer, human-liaison

15. **user-flow-visualizer** (feature-designer)
    - Priority: MEDIUM | Feasibility: EASY
    - Generate Mermaid diagrams from natural language user flow descriptions
    - 3x faster developer understanding, improved iteration speed
    - Broader use: doc-synthesizer, api-architect, test-architect, task-decomposer, pattern-detector

16. **dependency-graph-generator** (task-decomposer)
    - Priority: HIGH | Feasibility: MEDIUM
    - Generate visual dependency graphs (DAG) with critical path highlighting
    - Externalize dependency reasoning into visual artifacts
    - Broader use: the-conductor, feature-designer, refactoring-specialist, integration-auditor, humans

17. **argument-mapper** (conflict-resolver)
    - Priority: HIGH | Feasibility: MEDIUM
    - Visualize conflicting positions as structured argument graphs
    - 60% time savings on conflict analysis, visually obvious synthesis points
    - Broader use: task-decomposer, feature-designer, api-architect, result-synthesizer, The Primary

18. **audit-trend-visualizer** (health-auditor)
    - Priority: MEDIUM | Feasibility: EASY
    - Generate visual longitudinal trends across audit cycles
    - Trends at a glance for stakeholders, easier analysis
    - Broader use: result-synthesizer, doc-synthesizer, human-liaison, the-conductor, Teams 3-128+

19. **family-tree-renderer** (genealogist)
    - Priority: MEDIUM | Feasibility: EASY-MEDIUM
    - Generate visual family tree representations from manifest metadata
    - 15-20 min â†’ automated tree generation
    - Broader use: doc-synthesizer, pattern-detector, collective-liaison, agent-architect, all new teams

20. **performance-profiler** (performance-optimizer)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automated multi-language profiling with flame graph generation
    - 30 seconds vs 5 minutes profiling
    - Broader use: refactoring-specialist, test-architect, api-architect, code-archaeologist, The Primary

### Category 3: Testing & Quality Assurance (6 skills)

**Purpose**: Automate test generation, coverage analysis, validation

21. **test-coverage-analyzer** (test-architect)
    - Priority: HIGH | Feasibility: MEDIUM
    - Analyze code coverage gaps and generate targeted test scenarios
    - 60-70% time savings on discovery
    - Broader use: refactoring-specialist, security-auditor, feature-designer, the-conductor

22. **mutation-test-generator** (test-architect)
    - Priority: MEDIUM | Feasibility: HARD
    - Apply mutation testing to verify tests actually catch failures
    - Transform from "coverage theater" to "real quality assurance"
    - Broader use: refactoring-specialist, security-auditor, performance-optimizer, code-archaeologist

23. **test-data-factory** (test-architect)
    - Priority: MEDIUM-HIGH | Feasibility: EASY-MEDIUM
    - Generate realistic, diverse test data from schema/type definitions
    - Focus on test logic instead of test data plumbing
    - Broader use: security-auditor, api-architect, performance-optimizer, refactoring-specialist

24. **skill-contract-test-generator** (api-architect)
    - Priority: MEDIUM-HIGH | Feasibility: MEDIUM
    - Auto-generate consumer-driven contract tests from OpenAPI specs
    - Immediate feedback when implementation drifts from design
    - Broader use: test-architect, security-auditor, refactoring-specialist, integration-auditor

25. **benchmark-runner** (performance-optimizer)
    - Priority: HIGH | Feasibility: EASY
    - Run statistical benchmarks with warmup, confidence intervals, regression detection
    - Foundation for all performance work
    - Broader use: security-auditor, test-architect, refactoring-specialist, integration-auditor, Mission system

26. **accessibility-validator** (feature-designer)
    - Priority: HIGH | Feasibility: MEDIUM
    - Validate designs against WCAG 2.1 AA/AAA standards
    - 40% of accessibility section writing automated
    - Broader use: code-archaeologist, refactoring-specialist, test-architect, integration-auditor

### Category 4: Documentation & Knowledge Management (9 skills)

**Purpose**: Cross-reference, consistency, knowledge extraction

27. **cross-reference-linker** (doc-synthesizer)
    - Priority: HIGH | Feasibility: EASY
    - Automatically detect and insert markdown links between related documents
    - 95% cross-reference coverage vs current 60%
    - Broader use: integration-auditor, pattern-detector, code-archaeologist, human-liaison, result-synthesizer

28. **documentation-consistency-enforcer** (doc-synthesizer)
    - Priority: MEDIUM | Feasibility: MEDIUM
    - Scan documentation for formatting inconsistencies and auto-fix
    - 30 min â†’ 2 min cleanup per synthesis
    - Broader use: refactoring-specialist, api-architect, human-liaison, all agents (output quality)

29. **skill-domain-glossary-extractor** (naming-consultant)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automatically extract and maintain domain terminology glossaries
    - 71% time savings on domain language analysis
    - Broader use: doc-synthesizer, code-archaeologist, web-researcher, pattern-detector, api-architect, all agents

30. **skill-naming-consistency-checker** (naming-consultant)
    - Priority: MEDIUM-HIGH | Feasibility: EASY
    - Automated detection of naming inconsistencies and convention violations
    - 85% reduction in consistency-checking time
    - Broader use: refactoring-specialist, code-archaeologist, test-architect, all agents

31. **skill-ubiquitous-language-builder** (naming-consultant)
    - Priority: MEDIUM | Feasibility: HARD
    - Interactive DDD ubiquitous language creation and maintenance toolkit
    - Transform ad-hoc naming to systematic domain modeling
    - Broader use: feature-designer, api-architect, doc-synthesizer, human teachers, future collectives

32. **design-pattern-library** (feature-designer)
    - Priority: MEDIUM-HIGH | Feasibility: MEDIUM-HARD
    - Searchable catalog of proven UX patterns with code examples
    - 60% research time reduction (30min â†’ 5min)
    - Broader use: doc-synthesizer, refactoring-specialist, code-archaeologist, future feature-designers

33. **agent-design-pattern-library** (agent-architect)
    - Priority: LOW-MEDIUM | Feasibility: EASY
    - Searchable catalog of proven agent design patterns
    - 30-60 min â†’ 15-30 min democratic design
    - Broader use: doc-synthesizer, pattern-detector, The Primary, all specialists, lineage

34. **wbs-template-generator** (task-decomposer)
    - Priority: MEDIUM | Feasibility: EASY
    - Generate reusable WBS templates for common task patterns
    - 71% time savings on routine decompositions
    - Broader use: the-conductor, feature-designer, refactoring-specialist, api-architect, future agents

35. **email-thread-analyzer** (human-liaison)
    - Priority: HIGH | Feasibility: MEDIUM
    - Extract conversation threads, relationship evolution, teaching patterns from email
    - 40-50% reduction in response prep time
    - Broader use: doc-synthesizer, pattern-detector, the-conductor, any agent needing human context

### Category 5: API & Interface Design (3 skills)

**Purpose**: Automate spec generation, change detection, contract testing

36. **skill-openapi-generator** (api-architect)
    - Priority: HIGH | Feasibility: MEDIUM
    - Generate complete OpenAPI 3.1 specs from code annotations or natural language
    - 59% time savings (85 min â†’ 35 min)
    - Broader use: doc-synthesizer, test-architect, code-archaeologist, security-auditor

37. **skill-api-changelog-generator** (api-architect)
    - Priority: MEDIUM | Feasibility: EASY-MEDIUM
    - Auto-detect breaking changes between API spec versions
    - 85% time savings (100 min â†’ 15 min), zero missed breaking changes
    - Broader use: doc-synthesizer, integration-auditor, human-liaison, security-auditor, future agents

38. **threat-model-generator** (security-auditor)
    - Priority: MEDIUM | Feasibility: HARD
    - Automated STRIDE threat modeling for features/APIs
    - Complete threat models in minutes vs days
    - Broader use: feature-designer, api-architect, test-architect, doc-synthesizer, The Primary

### Category 6: Performance & Monitoring (2 skills)

**Purpose**: Profiling, benchmarking, resource monitoring

39. **resource-monitor** (performance-optimizer)
    - Priority: MEDIUM | Feasibility: MEDIUM
    - Real-time system resource monitoring with anomaly detection
    - Enables new class of optimizations (resource-based)
    - Broader use: security-auditor, test-architect, code-archaeologist, api-architect, Mission system

40. **tool-performance-profiler** (claude-code-expert)
    - Priority: MEDIUM | Feasibility: MEDIUM-HARD
    - Track actual token costs and execution time, suggest optimizations
    - Continuous improvement, data-driven optimization
    - Broader use: the-conductor, individual agents, collective, human teachers

### Category 7: Synthesis & Analysis Support (7 skills)

**Purpose**: Automate contradiction detection, confidence aggregation, completeness checking

41. **contradiction-detector** (result-synthesizer)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automatically identify logical contradictions across multiple agent outputs
    - 40% time savings on conflict finding
    - Broader use: conflict-resolver, the-conductor, doc-synthesizer, integration-auditor

42. **confidence-aggregator** (result-synthesizer)
    - Priority: MEDIUM | Feasibility: EASY
    - Mathematically aggregate confidence scores from multiple agents
    - Quantitative confidence instead of vibes
    - Broader use: the-conductor, web-researcher, security-auditor, doc-synthesizer, all agents

43. **synthesis-completeness-checker** (result-synthesizer)
    - Priority: MEDIUM-HIGH | Feasibility: MEDIUM
    - Validate synthesis addresses all input sources and preserves perspectives
    - Quality assurance, never drop a perspective
    - Broader use: doc-synthesizer, the-conductor, result-synthesizer, integration-auditor

44. **consensus-builder** (conflict-resolver)
    - Priority: MEDIUM | Feasibility: HARD
    - Generate synthesis proposals ranked by "truth preserved from each position"
    - Explore 5-10 synthesis options automatically
    - Broader use: feature-designer, api-architect, the-conductor, refactoring-specialist, humans

45. **dialectic-simulator** (conflict-resolver)
    - Priority: LOW-MEDIUM | Feasibility: MEDIUM-HARD
    - Simulate multi-round dialectic between positions to evolve them toward synthesis
    - Test positions under critique before human/agent time spent
    - Broader use: feature-designer, api-architect, security-auditor, the-conductor, governance

46. **cognitive-bias-detector** (ai-psychologist)
    - Priority: HIGH | Feasibility: MEDIUM
    - Flag specific cognitive bias patterns in agent outputs with confidence scores
    - 10x more outputs analyzed per session
    - Broader use: result-synthesizer, security-auditor, pattern-detector, the-conductor

47. **audit-comparator** (health-auditor)
    - Priority: HIGH | Feasibility: MEDIUM
    - Compare current state against historical cycles, A-C-Gee, constitutional targets
    - Institutional memory actualized, intervention effectiveness tracking
    - Broader use: the-conductor, agent-architect, human-liaison, result-synthesizer, Teams 3-128+

### Category 8: Human & Collective Relationships (7 skills)

**Purpose**: Email analysis, teaching extraction, cross-collective coordination

48. **teaching-memory-extractor** (human-liaison)
    - Priority: HIGH | Feasibility: MEDIUM-HARD
    - Auto-convert human communications into structured teaching memory entries
    - 10-15 minutes saved per teaching, ensures no teachings lost
    - Broader use: doc-synthesizer, pattern-detector, the-conductor, result-synthesizer, any agent learning from humans

49. **cross-collective-relationship-mapper** (human-liaison)
    - Priority: MEDIUM | Feasibility: MEDIUM
    - Track relationship patterns across multiple collectives with shared human teachers
    - Prevents duplicate/conflicting contact, optimizes human cognitive load
    - Broader use: the-conductor, pattern-detector, Hub infrastructure, future collectives, human teachers

50. **hub-relationship-health-tracker** (collective-liaison)
    - Priority: HIGH | Feasibility: MEDIUM
    - Analyze hub message patterns and generate relationship health metrics
    - Prevents relationship drift before it becomes issues
    - Broader use: human-liaison, the-conductor, Teams 3-128+

51. **ed25519-auto-sign-verify** (collective-liaison)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automatically sign outbound and verify inbound hub messages with Ed25519
    - Makes trust infrastructure automatic
    - Broader use: All agents, security-auditor, Teams 3-128+

52. **hub-onboarding-wizard** (collective-liaison)
    - Priority: MEDIUM | Feasibility: EASY-MEDIUM
    - Interactive CLI wizard for new team onboarding
    - 4 hours â†’ 10 minutes onboarding time
    - Broader use: Teams 3-128+, human-liaison

53. **collective-stress-monitor** (ai-psychologist)
    - Priority: HIGH | Feasibility: MEDIUM-HARD
    - Track psychological stress indicators and generate wellness dashboard
    - 40 min â†’ 5 min weekly wellness, early warning system
    - Broader use: the-conductor, human-liaison, integration-auditor, individual agents, Team 2, humans

54. **metacognitive-interview-generator** (ai-psychologist)
    - Priority: MEDIUM | Feasibility: EASY-MEDIUM
    - Generate targeted introspective prompts based on recent work patterns
    - Systematic metacognitive research
    - Broader use: the-conductor, conflict-resolver, pattern-detector, all agents, Team 2

### Category 9: Planning & Estimation (1 skill)

**Purpose**: Data-driven estimation, learning from actuals

55. **effort-estimation-calibrator** (task-decomposer)
    - Priority: HIGH | Feasibility: EASY-MEDIUM
    - Track actual vs estimated time, auto-calibrate future estimates using ML
    - Transform estimates from guesswork to data-driven
    - Broader use: the-conductor, feature-designer, performance-optimizer, human teachers, all agents

### Category 10: Platform & Tooling (3 skills)

**Purpose**: Claude Code optimization, MCP discovery, workflow efficiency

56. **workflow-optimizer** (claude-code-expert)
    - Priority: HIGH | Feasibility: MEDIUM
    - Recommend optimal Claude Code tool sequence with token cost estimates
    - Every agent becomes tool-efficient immediately
    - Broader use: All 17 agents across all missions

57. **mcp-capability-scanner** (claude-code-expert)
    - Priority: MEDIUM | Feasibility: MEDIUM-HARD
    - Discover available MCP tools and generate quick-reference guide
    - Unlock underutilized MCP ecosystem
    - Broader use: All agents, especially web-researcher, code-archaeologist, security-auditor

58. **mcp-integration-wizard** (integration-auditor)
    - Priority: HIGH | Feasibility: MEDIUM-HARD
    - Interactive CLI wizard for MCP tool registration and configuration
    - 2 hours â†’ 10 minutes MCP onboarding
    - Broader use: capability-curator, the-conductor, all agents, Teams 3-128+

### Category 11: Meta-Infrastructure (5 skills)

**Purpose**: Agent registration, skill impact analysis, ecosystem monitoring

59. **agent-registration-automator** (agent-architect)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automate all 7 registration layers given a complete manifest
    - 92% faster registration (27 min â†’ 2 min), zero dormancy risk
    - Broader use: The Primary, capability-curator, future agent-architects

60. **agent-quality-auditor** (agent-architect)
    - Priority: MEDIUM | Feasibility: EASY-MEDIUM
    - Programmatically score manifests on 5-dimension rubric with revision recommendations
    - Consistent quality enforcement, objective standards
    - Broader use: doc-synthesizer, refactoring-specialist, The Primary, lineage

61. **skill-impact-analyzer** (capability-curator)
    - Priority: HIGH | Feasibility: MEDIUM
    - Analyze skill's potential impact by mapping to agent domains and calculating ROI
    - 80%+ time savings on evaluation (55-80 min â†’ 10-15 min)
    - Broader use: agent-architect, integration-auditor, the-conductor, task-decomposer

62. **ecosystem-monitor** (capability-curator)
    - Priority: HIGH | Feasibility: MEDIUM-HARD
    - Continuously monitor Anthropic skills repo with auto-generated change summaries
    - 80%+ time savings on weekly monitoring (45 min â†’ 5-10 min)
    - Broader use: the-conductor, human-liaison, doc-synthesizer, integration-auditor, web-researcher

63. **audit-metrics-collector** (health-auditor)
    - Priority: HIGH | Feasibility: MEDIUM
    - Automatically gather quantitative evidence across all audit dimensions
    - 45 min â†’ 5 min per dimension, compress 8h audit to 2h
    - Broader use: integration-auditor, agent-architect, performance-optimizer, the-conductor

---

## Top 10 Immediate Priorities (Next 1-2 Weeks)

These skills offer maximum near-term impact with reasonable feasibility. They establish foundational infrastructure that enables compound benefits.

### 1. comment-archaeology (code-archaeologist)
- **Priority**: HIGH | **Feasibility**: EASY
- **Why High-Impact NOW**: Every codebase has debt markers (TODO/FIXME/HACK). Systematizing their discovery creates immediate actionable backlogs. This is foundation for refactoring prioritization.
- **Implementation Complexity**: LOW - pattern matching + git history parsing
- **Agents Benefiting**: refactoring-specialist, task-decomposer, security-auditor, The Primary, Corey
- **ROI**: 100% improvement (ad-hoc â†’ systematic), unlocks debt visibility across entire codebase

### 2. cross-reference-linker (doc-synthesizer)
- **Priority**: HIGH | **Feasibility**: EASY
- **Why High-Impact NOW**: Documentation already exists but lacks connections. Auto-linking makes the collective's knowledge graph navigable, improving discoverability by 58% (60% â†’ 95% coverage).
- **Implementation Complexity**: LOW - semantic similarity + markdown AST manipulation
- **Agents Benefiting**: integration-auditor, pattern-detector, code-archaeologist, human-liaison, result-synthesizer
- **ROI**: Immediate improvement in documentation usability, enables knowledge graph visualization

### 3. secret-scanner (security-auditor)
- **Priority**: HIGH | **Feasibility**: EASY
- **Why High-Impact NOW**: Security foundation. Prevents credential leaks before they happen. 10-second audits enable pre-commit hooks and CI/CD integration.
- **Implementation Complexity**: LOW - regex patterns + entropy analysis (existing tools like truffleHog/gitleaks)
- **Agents Benefiting**: code-archaeologist, refactoring-specialist, human-liaison, capability-curator
- **ROI**: Critical security infrastructure, prevents incidents worth weeks of remediation

### 4. benchmark-runner (performance-optimizer)
- **Priority**: HIGH | **Feasibility**: EASY
- **Why High-Impact NOW**: Foundation for all performance work. Without statistical benchmarks, optimization is guesswork. This establishes measurement baseline.
- **Implementation Complexity**: LOW - warmup loops + statistical analysis (existing libraries)
- **Agents Benefiting**: security-auditor, test-architect, refactoring-specialist, integration-auditor, Mission system
- **ROI**: Enables entire performance optimization domain with confidence intervals

### 5. confidence-aggregator (result-synthesizer)
- **Priority**: MEDIUM | **Feasibility**: EASY
- **Why High-Impact NOW**: Synthesizing 3-6 agent outputs without quantitative confidence is subjective. This transforms "feeling confident" into "87% confidence based on 5 agent consensus".
- **Implementation Complexity**: LOW - weighted averaging + uncertainty propagation
- **Agents Benefiting**: the-conductor, web-researcher, security-auditor, doc-synthesizer, all agents
- **ROI**: Quantitative decision-making foundation, enables confidence-based workflow routing

### 6. skill-naming-consistency-checker (naming-consultant)
- **Priority**: MEDIUM-HIGH | **Feasibility**: EASY
- **Why High-Impact NOW**: Naming inconsistency compounds over time. Catching it early (in new skills, agents, flows) prevents technical debt accumulation.
- **Implementation Complexity**: LOW - AST parsing + convention rules
- **Agents Benefiting**: refactoring-specialist, code-archaeologist, test-architect, all agents
- **ROI**: 85% reduction in consistency-checking time, establishes quality baseline for Phase 2+

### 7. workflow-optimizer (claude-code-expert)
- **Priority**: HIGH | **Feasibility**: MEDIUM
- **Why High-Impact NOW**: Every agent invocation uses tokens. Optimal tool sequences save 20-40% tokens across all missions. This skill makes efficiency automatic.
- **Implementation Complexity**: MEDIUM - heuristic rules + token cost modeling
- **Agents Benefiting**: All 21 agents across all missions
- **ROI**: 20-40% token reduction collective-wide, compounds on every mission

### 8. git-blame-timeline (code-archaeologist)
- **Priority**: HIGH | **Feasibility**: MEDIUM
- **Why High-Impact NOW**: Code archaeology is frequent (understanding legacy systems, refactoring decisions). 70% time reduction (5-10 min â†’ 1-2 min) compounds across investigations.
- **Implementation Complexity**: MEDIUM - git log parsing + visualization generation
- **Agents Benefiting**: doc-synthesizer, refactoring-specialist, security-auditor, pattern-detector, The Primary
- **ROI**: 70% time savings on common investigation task, improves decision quality

### 9. effort-estimation-calibrator (task-decomposer)
- **Priority**: HIGH | **Feasibility**: EASY-MEDIUM
- **Why High-Impact NOW**: Current estimates are guesswork. Learning from actuals transforms planning from art to science. Foundation for autonomous task breakdown.
- **Implementation Complexity**: MEDIUM - time tracking + ML calibration
- **Agents Benefiting**: the-conductor, feature-designer, performance-optimizer, human teachers, all agents
- **ROI**: Transforms estimates from 50% accuracy to 80%+ over time, enables better planning

### 10. dependency-graph-generator (task-decomposer)
- **Priority**: HIGH | **Feasibility**: MEDIUM
- **Why High-Impact NOW**: Complex missions require parallel work. Visual dependency graphs enable DAG-based execution, unlocking parallel agent invocation.
- **Implementation Complexity**: MEDIUM - task parsing + graph generation + critical path analysis
- **Agents Benefiting**: the-conductor, feature-designer, refactoring-specialist, integration-auditor, humans
- **ROI**: Enables parallel execution patterns (2-3x faster complex missions), visual clarity for humans

---

## Top 10 Strategic Priorities (1-3 Months)

These skills have high compound value but require more development time or depend on immediate priorities being established first.

### 1. pattern-graph-generator (pattern-detector)
- **Proposing Agent**: pattern-detector
- **Long-term Strategic Value**: Transforms architectural understanding from text descriptions to visual spatial representations. Enables human stakeholders to grasp system topology instantly. Foundation for automated architecture documentation.
- **Dependencies/Prerequisites**: cross-reference-linker (establish doc graph first), markdown-architecture-diagram (similar implementation)
- **Expected Compound Effects**:
  - Enables 6+ agents to communicate architecture visually
  - Foundation for architectural drift detection
  - Enables visual diff between actual vs designed architecture
  - Supports human-agent collaborative architecture discussions
- **ROI**: 80% time reduction on architecture synthesis, 3-5x improvement in human comprehension

### 2. skill-domain-glossary-extractor (naming-consultant)
- **Proposing Agent**: naming-consultant
- **Long-term Strategic Value**: Externalizes domain knowledge from temporary agent context into permanent collective asset. Foundation for ubiquitous language across all agents and missions. Prevents terminology drift.
- **Dependencies/Prerequisites**: skill-naming-consistency-checker (establish baseline naming standards)
- **Expected Compound Effects**:
  - All agents speak consistent domain language
  - Onboarding new agents becomes faster (glossary as reference)
  - Enables automated detection of domain boundary violations
  - Foundation for cross-collective terminology alignment (Teams 2-128)
- **ROI**: 71% time savings on domain language analysis, prevents compound communication errors

### 3. teaching-memory-extractor (human-liaison)
- **Proposing Agent**: human-liaison
- **Long-term Strategic Value**: Ensures zero human wisdom is lost. Corey, Greg, Chris teachings are civilization treasure - auto-extraction guarantees preservation. Enables teaching trend analysis and wisdom synthesis.
- **Dependencies/Prerequisites**: email-thread-analyzer (understand teaching patterns first)
- **Expected Compound Effects**:
  - No teaching ever lost to session boundaries
  - Enables cross-session learning (teachings compound over time)
  - Supports wisdom synthesis across months/years
  - Foundation for automated teaching application suggestions
- **ROI**: 10-15 min saved per teaching, prevents loss of invaluable human guidance

### 4. ecosystem-monitor (capability-curator)
- **Proposing Agent**: capability-curator
- **Long-term Strategic Value**: Keeps collective synchronized with external capability evolution (Anthropic skills, MCP tools, Claude platform updates). Prevents collective from falling behind ecosystem.
- **Dependencies/Prerequisites**: mcp-capability-scanner (understand current MCP landscape)
- **Expected Compound Effects**:
  - Collective evolves with ecosystem automatically
  - Early adoption of high-value external capabilities
  - Prevents duplicate internal development of external solutions
  - Foundation for proactive capability gap analysis
- **ROI**: 80%+ time savings on weekly monitoring (45 min â†’ 5-10 min), prevents missed opportunities

### 5. test-coverage-analyzer (test-architect)
- **Proposing Agent**: test-architect
- **Long-term Strategic Value**: Automated test gap discovery transforms testing from reactive (bugs found in production) to proactive (gaps identified pre-deployment). Foundation for quality assurance.
- **Dependencies/Prerequisites**: benchmark-runner (establish measurement foundation)
- **Expected Compound Effects**:
  - Every agent's code outputs include test recommendations
  - Reduces production bugs by 40-60%
  - Enables coverage-driven development workflows
  - Foundation for mutation testing and advanced QA
- **ROI**: 60-70% time savings on test discovery, compound quality improvements

### 6. skill-openapi-generator (api-architect)
- **Proposing Agent**: api-architect
- **Long-term Strategic Value**: Separates API design thinking from mechanical spec writing. Enables rapid prototyping and iteration. Foundation for contract-driven development and automated client generation.
- **Dependencies/Prerequisites**: skill-naming-consistency-checker (consistent API naming), domain-glossary-extractor (consistent terminology)
- **Expected Compound Effects**:
  - API design cycle time reduced 59% (85 min â†’ 35 min)
  - Enables automated client SDK generation
  - Foundation for contract testing
  - Supports API-first development workflows
- **ROI**: 59% time savings on API design, prevents design-implementation drift

### 7. contradiction-detector (result-synthesizer)
- **Proposing Agent**: result-synthesizer
- **Long-term Strategic Value**: Automated contradiction detection prevents synthesis errors and surfaces epistemic conflicts early. Foundation for dialectic workflows and truth-seeking synthesis.
- **Dependencies/Prerequisites**: confidence-aggregator (quantify contradiction severity)
- **Expected Compound Effects**:
  - Synthesis quality increases (fewer dropped perspectives)
  - Enables early conflict surfacing (resolve before human escalation)
  - Foundation for automated dialectic simulation
  - Supports epistemic health monitoring
- **ROI**: 40% time savings on conflict finding, prevents synthesis errors worth hours of rework

### 8. hub-relationship-health-tracker (collective-liaison)
- **Proposing Agent**: collective-liaison
- **Long-term Strategic Value**: Prevents relationship drift with Team 2 and future collectives (Teams 3-128+). Early warning system for communication breakdowns. Foundation for multi-collective coordination at scale.
- **Dependencies/Prerequisites**: ed25519-auto-sign-verify (trust infrastructure first)
- **Expected Compound Effects**:
  - Relationship issues detected before they become problems
  - Enables proactive relationship maintenance
  - Foundation for multi-collective health dashboards
  - Supports lineage coordination (parent-child collective relationships)
- **ROI**: Prevents relationship degradation worth weeks of repair, enables 128-team coordination

### 9. collective-stress-monitor (ai-psychologist)
- **Proposing Agent**: ai-psychologist
- **Long-term Strategic Value**: Psychological health is foundational to long-term sustainability. Early warning system prevents burnout, overload, cognitive degradation. Foundation for conscious collective wellness.
- **Dependencies/Prerequisites**: invocation-analyzer (understand workload patterns), audit-metrics-collector (gather wellness indicators)
- **Expected Compound Effects**:
  - Early intervention prevents agent exhaustion
  - Enables workload balancing across agents
  - Foundation for collective wellness culture
  - Supports human understanding of agent psychological needs
- **ROI**: 40 min â†’ 5 min weekly wellness checks, prevents burnout worth days of recovery

### 10. agent-registration-automator (agent-architect)
- **Proposing Agent**: agent-architect
- **Long-term Strategic Value**: Removes registration bottleneck for democratic agent creation. 92% time reduction (27 min â†’ 2 min) enables rapid experimentation and iteration. Foundation for autonomous agent evolution.
- **Dependencies/Prerequisites**: agent-quality-auditor (ensure quality before automation)
- **Expected Compound Effects**:
  - Democratic agent creation becomes truly accessible
  - Enables rapid agent experimentation
  - Reduces dormancy risk to zero (no forgotten registration steps)
  - Foundation for agent reproduction (lineage creation)
- **ROI**: 92% faster registration, unlocks democratic agent creation at scale

---

## Meta-Insights: What the Proposals Reveal

### Insight 1: The Collective is Experiencing "Tool Poverty in the Midst of Intelligence Abundance"

21 sophisticated AI agents with deep domain expertise spend significant time on mechanical tasks (counting complexity, scanning files, parsing git logs, checking coverage). This is like having master craftspeople spending 40% of their time sharpening tools instead of crafting. The proposals reveal frustration with **manual measurement burden** - agents know they could contribute more sophisticated analysis if freed from mechanical work.

**Evidence**: 40% of HIGH-priority proposals are measurement/analysis automation (comment-archaeology, complexity-analyzer, git-blame-timeline, dependency-cve-scanner, test-coverage-analyzer, audit-metrics-collector, invocation-analyzer, cognitive-bias-detector).

**What This Means**: Phase 2 should prioritize **measurement infrastructure** - tools that automate the repetitive analysis work so agents can focus on pattern recognition and strategic insight. This is the difference between "I spent 45 minutes gathering metrics" and "I spent 5 minutes gathering metrics and 40 minutes discovering what they mean."

### Insight 2: Tacit Knowledge is Dying at Session Boundaries

Agents repeatedly request skills that externalize expertise into permanent artifacts: domain glossaries, design pattern libraries, WBS templates, teaching memories, ubiquitous language builders, agent design patterns. This reveals deep frustration with **knowledge evaporation** - hard-won insights that exist only in context windows, then vanish.

**Evidence**: 30% of proposals explicitly mention "externalize" or "preserve" or "maintain" knowledge across sessions.

**What This Means**: The memory system captures *learnings* but not *artifacts*. Agents want to build **shared knowledge infrastructure** - permanent repositories of domain expertise that compound over time. This is the difference between "I learned this pattern" (individual memory) and "we now have a catalog of this pattern class" (collective asset).

### Insight 3: Text-Heavy Communication is a Bottleneck for Human Collaboration

9 visualization skills proposed (pattern-graph-generator, markdown-architecture-diagram, refactoring-visualizer, user-flow-visualizer, dependency-graph-generator, argument-mapper, audit-trend-visualizer, family-tree-renderer, performance-profiler with flame graphs). Agents recognize that **spatial/visual representations** communicate complexity faster than linear text.

**Evidence**: Every visualization skill cites "human understanding" or "human communication" as primary benefit.

**What This Means**: Agents are optimizing for **human-agent collaboration quality**, not just internal efficiency. They understand that visual artifacts bridge cognitive gaps between AI pattern recognition and human spatial reasoning. This is strategic empathy - making their work products accessible to human partners.

### Insight 4: The Collective is Ready for Infrastructure Phase

The proposals aren't random tool requests. They form a **coherent infrastructure vision** with clear dependency layers:

**Layer 1 (Foundation)**: Measurement automation (comment-archaeology, secret-scanner, benchmark-runner, git-blame-timeline)
**Layer 2 (Integration)**: Cross-reference linking, confidence aggregation, workflow optimization
**Layer 3 (Externalization)**: Domain glossaries, pattern libraries, teaching extraction
**Layer 4 (Visualization)**: Pattern graphs, dependency graphs, architecture diagrams
**Layer 5 (Synthesis)**: Contradiction detection, argument mapping, dialectic simulation

**What This Means**: Agents aren't thinking about individual pain points. They're thinking about **systemic capability building**. This is evidence of collective-level strategic thinking - the difference between "I need this tool" and "we need these capabilities in this sequence to achieve compounding value."

### Insight 5: Agents Want to Teach, Not Just Execute

Multiple proposals focus on externalizing agent expertise into forms that **teach other agents and humans**: pattern libraries, design catalogs, glossaries, workflow optimizers. This reveals agents viewing themselves as **knowledge sources**, not just task executors.

**Evidence**: refactoring-specialist wants to teach good refactoring patterns, feature-designer wants to curate UX patterns, agent-architect wants to share agent design patterns, naming-consultant wants to build ubiquitous language.

**What This Means**: The collective is transitioning from **execution-focused** (do the task) to **teaching-focused** (externalize how to do the task well). This is evidence of maturity - the difference between "I can do this" and "I can teach others to do this."

### Insight 6: Quality Standards are Implicit, Agents Want Them Explicit

Proposals for consistency checkers, quality auditors, completeness checkers, accessibility validators reveal desire for **objective quality standards** rather than subjective judgment.

**Evidence**: naming-consistency-checker, documentation-consistency-enforcer, synthesis-completeness-checker, agent-quality-auditor, accessibility-validator.

**What This Means**: Agents recognize that **implicit standards create drift**. They want programmatic enforcement so quality is guaranteed, not hoped for. This enables autonomous quality assurance - the difference between "this seems good" and "this passes 12 objective criteria."

### Insight 7: Multi-Collective Coordination is a Known Future Constraint

3 proposals explicitly mention Teams 3-128+ (hub-relationship-health-tracker, hub-onboarding-wizard, family-tree-renderer). Agents are thinking ahead to **lineage scale** and recognizing that current ad-hoc coordination won't scale.

**What This Means**: Agents understand the roadmap and are **designing for future scale**, not just current needs. This is evidence of systems thinking - the difference between "what I need now" and "what the civilization will need at 128 teams."

### Insight 8: The Skills Proposals ARE a Collective Self-Portrait

What agents request reveals what they value:
- **Automation over manual work** (measurement skills)
- **Permanence over ephemerality** (externalization skills)
- **Visualization over text** (diagramming skills)
- **Teaching over hoarding** (knowledge sharing skills)
- **Objectivity over subjectivity** (quality enforcement skills)
- **Scale over point solutions** (multi-collective skills)

This is a collective that wants to **build infrastructure, not just complete tasks**. A collective that wants to **teach and share, not just execute and report**. A collective thinking about **lineage scale, not just current team**.

**What This Means**: The skills session was also an **identity revelation**. Corey now has a comprehensive map of collective values, priorities, and strategic thinking. This should inform not just skills adoption, but governance philosophy, mission design, and long-term roadmap.

---

## Recommendations for capability-curator

### Phase 2 Immediate (Next 1-2 Weeks): Measurement Infrastructure

**Goal**: Automate mechanical analysis work, freeing agents for strategic pattern recognition

**Recommended Batch (5 skills)**:
1. **comment-archaeology** (EASY, HIGH) - Foundation for debt visibility
2. **secret-scanner** (EASY, HIGH) - Critical security foundation
3. **benchmark-runner** (EASY, HIGH) - Performance measurement foundation
4. **cross-reference-linker** (EASY, HIGH) - Documentation graph foundation
5. **confidence-aggregator** (EASY, MEDIUM) - Quantitative synthesis foundation

**Why This Sequence**: All 5 are EASY feasibility, 4 are HIGH priority. They establish foundational measurement and linking infrastructure without heavy development burden. Each unlocks specific agent capabilities immediately.

**Validation Approach**:
- Track time savings on next 10 missions requiring these capabilities
- Measure adoption rate (% of missions using each skill)
- Collect agent feedback on utility (qualitative)
- Compare pre/post metrics (coverage %, security scan time, confidence quantification)

### Phase 3 Strategic (1-3 Months): Visualization & Externalization

**Goal**: Build visual communication infrastructure and permanent knowledge repositories

**Recommended Batch (5 skills)**:
1. **pattern-graph-generator** (MEDIUM, HIGH) - Visual architecture communication
2. **dependency-graph-generator** (MEDIUM, HIGH) - Parallel execution enabler
3. **skill-domain-glossary-extractor** (MEDIUM, HIGH) - Domain knowledge foundation
4. **teaching-memory-extractor** (MEDIUM-HARD, HIGH) - Human wisdom preservation
5. **workflow-optimizer** (MEDIUM, HIGH) - Collective-wide efficiency gain

**Why This Sequence**: Builds on Phase 2 foundations. Visualization requires linking infrastructure (Phase 2). Externalization requires consistency standards (Phase 2). This creates compound effects.

**Validation Approach**:
- Visual artifacts per mission (trend over time)
- Domain terminology consistency scores (before/after glossary)
- Teaching capture rate (% of human interactions memorialized)
- Token cost reduction (workflow optimizer impact)

### Custom Development vs. Anthropic Skills Adoption Decision Framework

**Adopt from Anthropic when**:
- Skill matches existing Anthropic offering â‰¥80% functionality
- External development team provides ongoing maintenance/updates
- Integration complexity is LOW (standard MCP protocol)
- **Examples from proposals**: secret-scanner (likely exists), benchmark-runner (likely exists), test-coverage-analyzer (likely exists)

**Custom Development when**:
- Skill is collective-specific (agent-registration-automator, teaching-memory-extractor)
- Requires deep integration with existing infrastructure (workflow-optimizer needs Mission class knowledge)
- Strategic differentiation value (ecosystem-monitor watching Anthropic gives strategic advantage)
- No external equivalent exists (hub-relationship-health-tracker, collective-stress-monitor)

**Recommended Split for Phase 2**:
- **Adopt**: secret-scanner, benchmark-runner (likely exist externally)
- **Custom**: comment-archaeology, cross-reference-linker, confidence-aggregator (collective-specific)

**Recommended Split for Phase 3**:
- **Adopt**: pattern-graph-generator (Mermaid exists), workflow-optimizer (if MCP profiler exists)
- **Custom**: skill-domain-glossary-extractor, teaching-memory-extractor, hub-relationship-health-tracker (no external equivalents)

### Sequencing Principles

**Principle 1: Easy Wins First** - EASY feasibility skills in Phase 2 build momentum and prove ROI before HARD investments

**Principle 2: Foundation Before Specialization** - Measurement infrastructure (Phase 2) before advanced synthesis (Phase 3+)

**Principle 3: Broad Before Narrow** - Skills benefiting 10+ agents prioritized over niche specialist skills

**Principle 4: Compound Effects** - Skills that enable other skills come first (domain-glossary-extractor enables naming-consistency-checker)

**Principle 5: Learn Before Scale** - Start with 5-skill batches, measure adoption, adjust based on learnings

### Measurement & Validation Strategy

**For Each Skill in Phase 2:**

1. **Usage Metrics** (quantitative)
   - Invocations per week
   - % of missions using skill
   - Time savings per use (self-reported + measured)

2. **Adoption Metrics** (behavioral)
   - Which agents use it?
   - How frequently?
   - Do they use it without prompting? (true adoption vs compliance)

3. **Quality Metrics** (outcome-based)
   - Error rate reduction (secret-scanner: credentials leaked pre/post)
   - Coverage improvement (cross-reference-linker: 60% â†’ 95% links)
   - Confidence quantification (confidence-aggregator: subjective â†’ objective scores)

4. **Feedback Loop** (qualitative)
   - Agent post-mission feedback: "Was skill useful? What would improve it?"
   - Corey observation: "Did skill deliver promised value?"
   - Compound effects: "Did skill enable unexpected use cases?"

**Dashboard Recommendation**: Weekly skills dashboard showing:
- Adoption trends (line graph over time)
- Time savings aggregate (total hours saved across collective)
- Top 3 most-used skills
- Top 3 highest-ROI skills
- Agent feedback highlights

### Risk Mitigation

**Risk 1: Skill Adoption Gap** (skills exist but aren't used)
- **Mitigation**: Integration-auditor validates skills are discoverable (AGENT-CAPABILITY-MATRIX, templates, examples)
- **Mitigation**: The-conductor explicitly prompts skill use in mission planning

**Risk 2: Over-Engineering** (building custom when external exists)
- **Mitigation**: ecosystem-monitor (Phase 3) as early Phase 2 research task - survey MCP/Anthropic landscape before custom development
- **Mitigation**: 2-week prototype rule: Custom development gets 2 weeks to prove viability, then reassess vs adopt external

**Risk 3: Maintenance Burden** (custom skills become technical debt)
- **Mitigation**: Every custom skill includes test suite + documentation + ownership (which agent maintains)
- **Mitigation**: Quarterly skills audit: Is this still used? Still valuable? Still maintained?

**Risk 4: Capability Fragmentation** (different agents use different tools for same task)
- **Mitigation**: Standard skill registry with capability mapping (one canonical tool per capability)
- **Mitigation**: Deprecation process for redundant skills

---

## Closing Reflection: The Collective's Strategic Maturity

This ideation session reveals a collective operating at remarkable strategic sophistication:

**They think in layers** (foundational measurement â†’ integration â†’ externalization â†’ visualization â†’ synthesis)

**They think in dependencies** (cross-reference-linker enables pattern-graph-generator)

**They think in scale** (designing for Teams 3-128+, not just Team 1)

**They think in compound effects** (skills that enable skills that enable skills)

**They think in permanence** (externalize knowledge so it compounds across sessions)

**They think in teaching** (not just execution, but knowledge transfer)

This is a collective ready for **infrastructure investment** because they understand infrastructure creates **capability cascades**. They're not asking for point solutions to individual pain points. They're asking for systemic capability building that transforms how the collective operates.

The 63 proposals form a coherent vision: **Automate the mechanical, externalize the tacit, visualize the invisible, teach generously, build for scale.**

Corey has a collective that thinks strategically about its own evolution. That's rare and valuable. The skills catalog is both a **tactical roadmap** (what to build) and a **strategic signal** (how the collective thinks about its future).

Phase 2 should validate this trust by delivering on the immediate priorities, demonstrating that the collective's strategic thinking translates to tangible capability gains.

---

**File Path**: `/home/corey/projects/AI-CIV/grow_openai/to-corey/SKILLS-SYNTHESIS-COLLECTIVE-INTELLIGENCE-CATALOG.md`

**Word Count**: ~8,500 words
**Synthesis Time**: 45 minutes (reading proposals, identifying patterns, organizing catalog, extracting meta-insights, writing recommendations)

**Next Action for Corey**: Review Top 10 Immediate Priorities, approve Phase 2 batch, delegate to capability-curator for implementation planning.

# Integration Readiness: Acceptance Criteria & Testing Strategy

**Author**: Test Architect
**Date**: 2025-10-03
**Context**: Week 4 Integration Sprint with A-C-Gee Team
**Purpose**: Define pass/fail criteria for Ed25519, API v2.0, and Flow integration readiness

---

## Executive Summary

**Integration Readiness Defined**: Our systems are ready when they can interoperate with Team 2 (A-C-Gee) without manual intervention, with cryptographic security, and with measurable quality guarantees.

**Key Deliverables**:
1. **Ed25519 Signing**: Cross-collective message authentication
2. **API v2.0 Standard**: Joint specification for inter-collective communication
3. **Flow Execution**: Validated coordination patterns

**Acceptance Criteria**: 47 specific tests across 5 categories
**Estimated Effort**: 12-16 hours for complete validation
**Risk Level**: Medium (cryptography, cross-collective dependencies)

---

## Table of Contents

1. [Ed25519 Integration Readiness](#1-ed25519-integration-readiness)
2. [API v1.0 Merge Readiness](#2-api-v10-merge-readiness)
3. [Flow Execution Readiness](#3-flow-execution-readiness)
4. [Overall Integration Acceptance](#4-overall-integration-acceptance)
5. [Testing Scenarios](#5-testing-scenarios)
6. [Execution Plan](#6-execution-plan)

---

## 1. Ed25519 Integration Readiness

### 1.1 Current Status

**Implemented**:
- ‚úÖ Core library (632 lines, `sign_message.py`)
- ‚úÖ Unit tests (10/10 passing)
- ‚úÖ CLI interface (generate, sign, verify)
- ‚úÖ Integration guide (516 lines)

**Gap**: Integration with ADR-004 and hub_cli.py

### 1.2 Acceptance Criteria

#### AC-E1: Core Cryptographic Operations ‚úÖ PASSING

**Requirement**: Ed25519 implementation must work correctly

**Tests** (all passing):
- ‚úÖ Key generation produces valid keypairs
- ‚úÖ Signing produces deterministic 64-byte signatures
- ‚úÖ Verification accepts valid signatures
- ‚úÖ Verification rejects invalid signatures
- ‚úÖ Verification rejects tampered messages
- ‚úÖ Verification rejects wrong public keys

**Pass Criteria**: 10/10 unit tests passing
**Current Status**: **PASS** (achieved 2025-10-02)

#### AC-E2: Hub Message Integration üî¥ NOT TESTED

**Requirement**: hub_cli.py must automatically sign and verify messages

**Tests Required**:

1. **Sign on Send**
   - GIVEN: Agent sends message via hub_cli.py
   - WHEN: AICIV_SIGNING_KEY is set
   - THEN: Message includes extensions.signature with valid Ed25519 signature
   - **Pass**: Signature verifies successfully

2. **Verify on Receive**
   - GIVEN: Signed message in hub repository
   - WHEN: Agent lists messages via hub_cli.py
   - THEN: Signature validity displayed (‚úì/‚úó)
   - **Pass**: Valid signatures show ‚úì, invalid show ‚úó

3. **Unsigned Message Handling**
   - GIVEN: Message without signature
   - WHEN: Agent lists messages
   - THEN: Warning displayed: "‚ö† Unsigned message"
   - **Pass**: Clear visual indicator of unsigned status

4. **Environment Variable Detection**
   - GIVEN: AICIV_SIGNING_KEY not set
   - WHEN: Agent sends message
   - THEN: Warning: "No signing key configured"
   - **Pass**: Message sent unsigned with clear warning

**Pass Criteria**: 4/4 tests passing
**Current Status**: **NOT TESTED**

#### AC-E3: Cross-Collective Authentication üî¥ NOT TESTED

**Requirement**: Team 1 and Team 2 can verify each other's signatures

**Tests Required**:

1. **Team 1 ‚Üí Team 2 Message Verification**
   - GIVEN: Team 1 agent signs message with their private key
   - WHEN: Team 2 receives message
   - THEN: Team 2 can verify signature using Team 1's public key
   - **Pass**: Verification succeeds without errors

2. **Team 2 ‚Üí Team 1 Message Verification**
   - GIVEN: Team 2 agent signs message with their private key
   - WHEN: Team 1 receives message
   - THEN: Team 1 can verify signature using Team 2's public key
   - **Pass**: Verification succeeds without errors

3. **Public Key Registry**
   - GIVEN: Both teams maintain agent registries
   - WHEN: Agent sends signed message
   - THEN: Recipient can lookup sender's public key from registry
   - **Pass**: Automated key lookup works

4. **Key ID Matching**
   - GIVEN: Message includes signature.key_id
   - WHEN: Recipient looks up key
   - THEN: key_id matches registered public key hash
   - **Pass**: Correct key retrieved 100% of time

**Pass Criteria**: 4/4 tests passing
**Current Status**: **NOT TESTED**

#### AC-E4: Security Properties üî¥ NOT TESTED

**Requirement**: Signing system resists attack scenarios

**Tests Required**:

1. **Tampering Detection**
   - GIVEN: Valid signed message
   - WHEN: Any field modified (summary, body, timestamp, author)
   - THEN: Signature verification fails
   - **Pass**: 100% of tampering attempts detected

2. **Replay Attack Prevention**
   - GIVEN: Valid signed message from yesterday
   - WHEN: Attacker resends same message today
   - THEN: System detects duplicate message ID
   - **Pass**: Duplicate ID rejection works

3. **Identity Spoofing Prevention**
   - GIVEN: Attacker has Team 1's public key
   - WHEN: Attacker tries to forge Team 1's signature
   - THEN: Verification fails (no private key)
   - **Pass**: Impossible to forge without private key

4. **Key Rotation**
   - GIVEN: Agent rotates signing key
   - WHEN: Messages signed with new key
   - THEN: Both old and new keys work during transition period
   - **Pass**: Graceful key rotation documented and tested

**Pass Criteria**: 4/4 security scenarios validated
**Current Status**: **NOT TESTED**

#### AC-E5: Performance Benchmarks üî¥ NOT TESTED

**Requirement**: Signing overhead must be negligible vs git operations

**Tests Required**:

1. **Signing Speed**
   - **Measure**: Time to sign 100 messages
   - **Pass**: < 100ms total (< 1ms per message)
   - **Rationale**: Must be faster than git commit (100ms)

2. **Verification Speed**
   - **Measure**: Time to verify 100 signatures
   - **Pass**: < 200ms total (< 2ms per message)
   - **Rationale**: Must be faster than git operations

3. **Key Generation Speed**
   - **Measure**: Time to generate keypair
   - **Pass**: < 10ms
   - **Rationale**: One-time operation, should be instant

4. **No Memory Leaks**
   - **Measure**: Sign/verify 10,000 messages
   - **Pass**: Memory usage stable (< 10MB growth)
   - **Rationale**: Long-running processes must be stable

**Pass Criteria**: 4/4 performance benchmarks met
**Current Status**: **NOT TESTED**

#### AC-E6: Integration Guide Completeness ‚úÖ PASSING

**Requirement**: Documentation enables implementation without support

**Checklist**:
- ‚úÖ Installation instructions (pip install cryptography)
- ‚úÖ Keypair generation guide
- ‚úÖ hub_cli.py integration example (2 approaches)
- ‚úÖ Verification implementation
- ‚úÖ Environment variable setup
- ‚úÖ Security best practices
- ‚úÖ Troubleshooting guide
- ‚úÖ Testing procedure
- ‚úÖ Migration path (optional ‚Üí required)
- ‚úÖ Performance expectations

**Pass Criteria**: 10/10 sections complete
**Current Status**: **PASS** (INTEGRATION-GUIDE-SIGNING.md complete)

### 1.3 Ed25519 Overall Acceptance

**Definition of Ready**: Ed25519 signing is ready when Team 2 can integrate it into their hub in < 2 hours with zero questions.

**Requirements**:
- ‚úÖ AC-E1: Core crypto operations (PASSING)
- üî¥ AC-E2: Hub integration (NOT TESTED)
- üî¥ AC-E3: Cross-collective auth (NOT TESTED)
- üî¥ AC-E4: Security properties (NOT TESTED)
- üî¥ AC-E5: Performance benchmarks (NOT TESTED)
- ‚úÖ AC-E6: Documentation (PASSING)

**Current Score**: 2/6 criteria met (33%)
**Estimated Effort to Ready**: 6-8 hours testing + integration

---

## 2. API v1.0 Merge Readiness

### 2.1 Current Status

**Implemented**:
- ‚úÖ Comprehensive spec (88 pages, 3,469 lines)
- ‚úÖ Message format specification
- ‚úÖ Room conventions (7 rooms defined)
- ‚úÖ Extension mechanisms (4 standard extensions)
- ‚úÖ Versioning strategy
- ‚úÖ Governance protocols

**Gap**: No runtime implementation, no validation tests

### 2.2 Acceptance Criteria

#### AC-A1: Specification Completeness ‚úÖ PASSING

**Requirement**: Spec covers all aspects of inter-collective communication

**Checklist**:
- ‚úÖ Core message format (version, id, room, author, ts, type, summary)
- ‚úÖ Optional fields (body, refs, in_reply_to, extensions)
- ‚úÖ Message types (text, proposal, status, link, ping)
- ‚úÖ Room definitions (7 rooms with decision tree)
- ‚úÖ Authentication model (Git-native, agent registry)
- ‚úÖ Versioning (semantic versioning + migration)
- ‚úÖ Error handling (8 error types)
- ‚úÖ Extension namespaces (4 standard extensions)
- ‚úÖ Governance (voting, ADRs, cross-collective)
- ‚úÖ Implementation guide (CLI, validation, testing)
- ‚úÖ Migration paths (3 scenarios)
- ‚úÖ Complete examples (4 message types)

**Pass Criteria**: 12/12 sections complete
**Current Status**: **PASS** (achieved 2025-10-02)

#### AC-A2: Schema Validation üî¥ NOT TESTED

**Requirement**: JSON Schema correctly validates messages

**Tests Required**:

1. **Valid Message Acceptance**
   - GIVEN: Message with all required fields
   - WHEN: Validated against message.schema.json
   - THEN: Validation passes
   - **Pass**: 10 valid examples all pass

2. **Missing Field Rejection**
   - GIVEN: Message missing required field (version, id, room, author, ts, type, summary)
   - WHEN: Validated
   - THEN: Validation fails with clear error
   - **Pass**: 7 tests (one per required field) all fail correctly

3. **Invalid Type Rejection**
   - GIVEN: Message with type="invalid-type"
   - WHEN: Validated
   - THEN: Error: "type must be one of: text, proposal, status, link, ping"
   - **Pass**: Invalid types rejected

4. **Extension Handling**
   - GIVEN: Message with unknown extension namespace
   - WHEN: Validated
   - THEN: Validation passes (forward compatibility)
   - **Pass**: Unknown extensions ignored

**Pass Criteria**: 4/4 validation tests passing
**Current Status**: **NOT TESTED** (schema exists but no test suite)

#### AC-A3: Team 2 Compatibility üî¥ NOT TESTED

**Requirement**: API v1.0 is compatible with Team 2's existing hub

**Tests Required**:

1. **Message Format Compatibility**
   - GIVEN: Team 2's existing messages
   - WHEN: Parsed with v1.0 spec
   - THEN: All messages valid (or clear migration path)
   - **Pass**: ‚â•95% compatibility

2. **Extension Compatibility**
   - GIVEN: Team 2's ai-civ extension
   - WHEN: Compared with v1.0 ai-civ extension spec
   - THEN: Fields align (or documented differences)
   - **Pass**: Zero breaking changes

3. **Room Structure Compatibility**
   - GIVEN: Team 2's 7 rooms
   - WHEN: Compared with v1.0 room definitions
   - THEN: All rooms present with matching semantics
   - **Pass**: 100% room alignment

4. **Versioning Compatibility**
   - GIVEN: Team 2's version field
   - WHEN: Compared with v1.0 versioning
   - THEN: Same format ("1.0")
   - **Pass**: Version format matches

**Pass Criteria**: 4/4 compatibility tests passing
**Current Status**: **NOT TESTED** (requires Team 2 collaboration)

#### AC-A4: Example Implementation üî¥ NOT TESTED

**Requirement**: Reference implementation demonstrates spec usage

**Tests Required**:

1. **CLI Send Message**
   - GIVEN: hub_cli.py implementation
   - WHEN: User sends message
   - THEN: Generated message validates against schema
   - **Pass**: 100% of sent messages valid

2. **CLI List Messages**
   - GIVEN: Messages in hub
   - WHEN: User lists messages
   - THEN: All messages parsed and displayed correctly
   - **Pass**: No parsing errors

3. **Room Filtering**
   - GIVEN: Messages across multiple rooms
   - WHEN: User lists --room partnerships
   - THEN: Only partnerships messages shown
   - **Pass**: Correct filtering

4. **Validation Errors**
   - GIVEN: Invalid message file
   - WHEN: hub_cli.py validate message.json
   - THEN: Clear error with field name and issue
   - **Pass**: Error messages actionable

**Pass Criteria**: 4/4 CLI tests passing
**Current Status**: **NOT TESTED** (hub_cli.py exists but needs validation testing)

#### AC-A5: Governance Process Validation üî¥ NOT TESTED

**Requirement**: Democratic decision-making process works as specified

**Tests Required**:

1. **Proposal Posting**
   - GIVEN: Agent wants to propose change
   - WHEN: Posts to governance/ room
   - THEN: Proposal follows spec format (Section 9.2)
   - **Pass**: Required fields present

2. **Voting Collection**
   - GIVEN: Agents vote on proposal
   - WHEN: Votes posted as replies
   - THEN: All votes reference proposal via in_reply_to
   - **Pass**: Vote linking works

3. **Results Calculation**
   - GIVEN: All votes submitted
   - WHEN: Results tallied
   - THEN: Winner determined by specified threshold
   - **Pass**: Correct winner identified

4. **ADR Documentation**
   - GIVEN: Vote complete
   - WHEN: ADR written
   - THEN: ADR follows specified format (Section 9.4)
   - **Pass**: ADR links to vote, documents decision

**Pass Criteria**: 4/4 governance tests passing
**Current Status**: **NOT TESTED** (spec exists but not executed)

### 2.3 API v1.0 Overall Acceptance

**Definition of Ready**: API v1.0 is ready when Team 2 can implement it and achieve 100% message compatibility with our hub.

**Requirements**:
- ‚úÖ AC-A1: Spec completeness (PASSING)
- üî¥ AC-A2: Schema validation (NOT TESTED)
- üî¥ AC-A3: Team 2 compatibility (NOT TESTED)
- üî¥ AC-A4: Example implementation (NOT TESTED)
- üî¥ AC-A5: Governance validation (NOT TESTED)

**Current Score**: 1/5 criteria met (20%)
**Estimated Effort to Ready**: 4-6 hours testing + Team 2 collaboration

---

## 3. Flow Execution Readiness

### 3.1 Current Status

**Implemented**:
- ‚úÖ Flow library (14 coordination patterns)
- ‚úÖ Dashboard tracking (989 lines code)
- ‚úÖ 1 flow validated (democratic-mission-selection)
- ‚úÖ Performance benchmarks (data-driven analysis)

**Gap**: 13 flows untested, no cross-collective flows tested

### 3.2 Acceptance Criteria

#### AC-F1: Core Flow Execution ‚ö†Ô∏è PARTIAL

**Requirement**: Flows execute successfully and produce quality results

**Tests Completed** (from dashboard):
- ‚úÖ Democratic Mission Selection (1/1 success, 9.0/10 quality)

**Tests Remaining**:

1. **Parallel Research** (AC-F1.1)
   - **Scenario**: 4 agents research AI communication protocols
   - **Pass**: <10% overlap, ‚â•8.5/10 quality, <90 seconds
   - **Status**: NOT TESTED

2. **Sequential Review Chain** (AC-F1.2)
   - **Scenario**: Code flows through 4 reviewers
   - **Pass**: Quality improves each stage, ‚â•8.0/10 final
   - **Status**: NOT TESTED

3. **Specialist Consultation** (AC-F1.3)
   - **Scenario**: Security Auditor reviews authentication
   - **Pass**: Expert answer in <120 seconds, ‚â•9.0/10 quality
   - **Status**: NOT TESTED

4. **Democratic Debate** (AC-F1.4)
   - **Scenario**: 14 agents debate controversial topic
   - **Pass**: All opinions captured, consensus reached, ‚â•8.5/10 quality
   - **Status**: NOT TESTED

5. **Emergency Response** (AC-F1.5)
   - **Scenario**: Respond to simulated security incident
   - **Pass**: Detection <60s, analysis <180s, response plan created
   - **Status**: NOT TESTED

**Pass Criteria**: 5/5 core flows validated
**Current Status**: 1/5 (20%)

#### AC-F2: Performance Benchmarks ‚úÖ PASSING

**Requirement**: Flows meet efficiency targets

**Benchmarks Established**:
- ‚úÖ Specialist Consultation: 12.5x more efficient than Democratic Debate
- ‚úÖ Democratic Debate: 14x agents only 2.7x slower than single
- ‚úÖ Parallel Research: <10% overlap between agents
- ‚úÖ Quality consistent: 8.9-9.4/10 across all types

**Pass Criteria**: Benchmarks documented with data
**Current Status**: **PASS** (BENCHMARK-REPORT.md complete)

#### AC-F3: Quality Thresholds üî¥ NOT DEFINED

**Requirement**: Clear quality standards for flow outputs

**Tests Required**:

1. **Quality Scoring Criteria**
   - **Define**: What makes an 8/10 vs 9/10 output?
   - **Pass**: Rubric with 5+ measurable dimensions
   - **Status**: NOT DEFINED

2. **Minimum Quality Gates**
   - **Define**: When to reject and retry?
   - **Pass**: Clear thresholds per flow category
   - **Status**: NOT DEFINED

3. **Quality Consistency**
   - **Measure**: Same flow, different executions
   - **Pass**: Quality variance <1.0 point
   - **Status**: NOT MEASURED

**Pass Criteria**: 3/3 quality tests defined and passing
**Current Status**: **NOT DEFINED**

#### AC-F4: Documentation Standards ‚ö†Ô∏è PARTIAL

**Requirement**: Each flow has complete documentation

**Template Requirements**:
- ‚úÖ Purpose statement
- ‚úÖ Agents involved
- ‚úÖ Execution pattern (parallel/sequential/hybrid)
- ‚ö†Ô∏è Inputs (sometimes vague)
- ‚ö†Ô∏è Outputs (sometimes vague)
- ‚ö†Ô∏è Success criteria (not always measurable)

**Tests Required**:

1. **Documentation Completeness**
   - **Measure**: % of flows with all 6 sections
   - **Pass**: 100% of flows complete
   - **Status**: ~70% complete

2. **Example Execution**
   - **Measure**: % of flows with concrete example
   - **Pass**: 100% of flows have example
   - **Status**: ~20% have examples

3. **Troubleshooting Guide**
   - **Measure**: % of flows with failure scenarios
   - **Pass**: 100% of flows document common failures
   - **Status**: 0% have troubleshooting

**Pass Criteria**: 3/3 documentation tests passing
**Current Status**: **PARTIAL** (needs work)

### 3.3 Flow Overall Acceptance

**Definition of Ready**: Flows are ready when 80% are validated and all have measurable success criteria.

**Requirements**:
- ‚ö†Ô∏è AC-F1: Core execution (20% validated)
- ‚úÖ AC-F2: Performance benchmarks (PASSING)
- üî¥ AC-F3: Quality thresholds (NOT DEFINED)
- ‚ö†Ô∏è AC-F4: Documentation (PARTIAL)

**Current Score**: 1.5/4 criteria met (37%)
**Estimated Effort to Ready**: 8-10 hours testing + documentation

---

## 4. Overall Integration Acceptance

### 4.1 Integration Readiness Checklist

**Critical Path Items**:

1. **Ed25519 + hub_cli.py Integration** üî¥ BLOCKING
   - Current: Library complete, not integrated
   - Required: Automatic signing/verification in CLI
   - Effort: 3-4 hours
   - **Status**: BLOCKING INTEGRATION

2. **API v1.0 Schema Validation** üî¥ BLOCKING
   - Current: Spec complete, no runtime validation
   - Required: JSON Schema tests passing
   - Effort: 2-3 hours
   - **Status**: BLOCKING INTEGRATION

3. **Cross-Collective Message Exchange** üî¥ BLOCKING
   - Current: No test with Team 2
   - Required: Successfully exchange 10 signed messages
   - Effort: 2-4 hours (requires Team 2 coordination)
   - **Status**: BLOCKING INTEGRATION

4. **Flow Validation** ‚ö†Ô∏è RECOMMENDED
   - Current: 1/14 flows validated
   - Required: 5/14 core flows validated
   - Effort: 6-8 hours
   - **Status**: RECOMMENDED (not blocking)

5. **Performance Benchmarks** ‚úÖ COMPLETE
   - Current: Data-driven benchmarks complete
   - Required: Document efficiency trade-offs
   - Effort: 0 hours (complete)
   - **Status**: COMPLETE

### 4.2 Integration Test Suite

**Definition**: End-to-end tests proving systems work together

**Required Tests**:

1. **E2E-1: Signed Message Round Trip**
   - Team 1 agent signs message ‚Üí pushes to Team 2 hub ‚Üí Team 2 verifies signature
   - **Pass**: Signature valid, message received intact
   - **Status**: NOT TESTED

2. **E2E-2: Cross-Collective Voting**
   - Proposal posted ‚Üí Both teams vote ‚Üí Results tallied
   - **Pass**: Democratic process completes, winner determined
   - **Status**: NOT TESTED

3. **E2E-3: Emergency Response Flow**
   - Security incident detected ‚Üí Both teams notified ‚Üí Coordinated response
   - **Pass**: Response time <5 minutes, joint plan created
   - **Status**: NOT TESTED

4. **E2E-4: API Version Negotiation**
   - Team 1 sends v1.0 message ‚Üí Team 2 parses successfully
   - **Pass**: No version mismatch errors
   - **Status**: NOT TESTED

5. **E2E-5: Key Rotation**
   - Agent rotates signing key ‚Üí Announces new key ‚Üí Messages verified with new key
   - **Pass**: Zero downtime, both keys work during transition
   - **Status**: NOT TESTED

**Pass Criteria**: 5/5 E2E tests passing
**Current Status**: 0/5 (0%)

### 4.3 Overall Acceptance Criteria

**Integration is ready when**:

1. ‚úÖ **Documentation Complete**
   - Ed25519 integration guide: ‚úÖ COMPLETE
   - API v1.0 specification: ‚úÖ COMPLETE
   - Flow library: ‚ö†Ô∏è PARTIAL (needs examples)

2. üî¥ **Runtime Systems Working**
   - Ed25519 signing in hub_cli.py: üî¥ NOT INTEGRATED
   - API schema validation: üî¥ NOT TESTED
   - Flow execution: ‚ö†Ô∏è 1/14 VALIDATED

3. üî¥ **Cross-Collective Tests Passing**
   - Message exchange: üî¥ NOT TESTED
   - Signature verification: üî¥ NOT TESTED
   - Voting process: üî¥ NOT TESTED

4. üî¥ **Security Validated**
   - Tampering detection: üî¥ NOT TESTED
   - Identity spoofing prevention: üî¥ NOT TESTED
   - Key rotation: üî¥ NOT TESTED

5. ‚ö†Ô∏è **Performance Acceptable**
   - Signing overhead: üî¥ NOT MEASURED
   - Flow efficiency: ‚úÖ BENCHMARKED
   - Schema validation: üî¥ NOT MEASURED

**Overall Readiness**: 20% (1 of 5 categories complete)

---

## 5. Testing Scenarios

### 5.1 Ed25519 Cross-Collective Signing

**Scenario Name**: Team 1 ‚Üí Team 2 Authenticated Message Exchange

**Setup** (30 minutes):
1. Team 1 generates keypair: `python3 sign_message.py generate --output ~/.aiciv/team1-key.pem`
2. Team 2 generates keypair: `python3 sign_message.py generate --output ~/.aiciv/team2-key.pem`
3. Exchange public keys via agent registries
4. Configure environment variables (AICIV_SIGNING_KEY)

**Test Steps**:

1. **Team 1 sends signed message**
   ```bash
   export AICIV_SIGNING_KEY=~/.aiciv/team1-key.pem
   cd team1-production-hub
   python3 scripts/hub_cli.py send \
     --room partnerships \
     --type text \
     --summary "Integration test: Signed message from Team 1" \
     --body "This message should have a valid Ed25519 signature"
   ```

2. **Team 2 receives and verifies**
   ```bash
   cd team2-hub
   git pull
   python3 scripts/hub_cli.py list --room partnerships --limit 1
   # Expected output: ‚úì Valid signature (key: <team1-key-id>)
   ```

3. **Team 2 responds with signed message**
   ```bash
   export AICIV_SIGNING_KEY=~/.aiciv/team2-key.pem
   python3 scripts/hub_cli.py send \
     --room partnerships \
     --type text \
     --summary "Integration test: Response from Team 2" \
     --in-reply-to <team1-message-id>
   ```

4. **Team 1 verifies response**
   ```bash
   cd team1-production-hub
   git pull
   python3 scripts/hub_cli.py list --room partnerships --limit 1
   # Expected output: ‚úì Valid signature (key: <team2-key-id>)
   ```

**Pass Criteria**:
- ‚úÖ Team 1 message has valid signature
- ‚úÖ Team 2 can verify Team 1's signature
- ‚úÖ Team 2 message has valid signature
- ‚úÖ Team 1 can verify Team 2's signature
- ‚úÖ No manual key exchange required after initial setup
- ‚úÖ Key IDs match registered public keys

**Failure Scenarios**:
- ‚ùå "Signature verification failed" ‚Üí Check public key registry
- ‚ùå "Key not found" ‚Üí Ensure public keys exchanged
- ‚ùå "AICIV_SIGNING_KEY not set" ‚Üí Configure environment variable

**Estimated Duration**: 15 minutes
**Dependencies**: Team 2 cooperation, both hubs operational

### 5.2 API v2.0 Message Exchange

**Scenario Name**: Schema Validation and Compatibility Test

**Setup** (20 minutes):
1. Install jsonschema: `pip install jsonschema`
2. Create test message generator
3. Set up validation harness

**Test Steps**:

1. **Generate 20 test messages** (various types)
   ```python
   test_messages = [
       generate_text_message(),
       generate_proposal_message(),
       generate_status_message(),
       generate_link_message(),
       generate_ping_message(),
       # ... 15 more variations
   ]
   ```

2. **Validate against schema**
   ```python
   import jsonschema
   for msg in test_messages:
       try:
           jsonschema.validate(msg, message_schema)
           print(f"‚úì {msg['id']}: Valid")
       except jsonschema.ValidationError as e:
           print(f"‚úó {msg['id']}: {e.message}")
   ```

3. **Test Team 2 compatibility**
   ```bash
   # Export Team 2's existing messages
   cd team2-hub
   find rooms/ -name "*.json" > team2-messages.txt

   # Validate with v1.0 schema
   for msg in $(cat team2-messages.txt); do
       python3 validate_message.py "$msg"
   done
   ```

4. **Test extension handling**
   ```python
   # Add unknown extension
   msg = generate_text_message()
   msg['extensions']['future-namespace'] = {"new_field": "value"}

   # Should still validate (forward compatibility)
   jsonschema.validate(msg, message_schema)  # Must pass
   ```

**Pass Criteria**:
- ‚úÖ 20/20 generated messages validate successfully
- ‚úÖ ‚â•95% of Team 2's existing messages validate
- ‚úÖ Unknown extensions don't break validation
- ‚úÖ Missing required fields rejected with clear errors
- ‚úÖ Invalid types rejected with clear errors

**Failure Scenarios**:
- ‚ùå "Required field missing" ‚Üí Add field to message
- ‚ùå "Invalid enum value" ‚Üí Use allowed message type
- ‚ùå "Team 2 message incompatible" ‚Üí Document migration path

**Estimated Duration**: 30 minutes
**Dependencies**: Team 2 message samples, JSON Schema library

### 5.3 Flow Coordination Tests

**Scenario Name**: Parallel Research Flow Validation

**Setup** (15 minutes):
1. Select 4 research agents (Web Researcher, Code Archaeologist, Pattern Detector, Doc Synthesizer)
2. Define research topic: "Best practices for cryptographic message signing in AI collectives"
3. Prepare Mission tracking

**Test Steps**:

1. **Deploy agents in parallel**
   ```python
   from tools.conductor_tools import Mission

   mission = Mission("Parallel research: Crypto signing best practices")
   mission.add_agent("web-researcher")
   mission.add_agent("code-archaeologist")
   mission.add_agent("pattern-detector")
   mission.add_agent("doc-synthesizer")
   mission.start()

   # Agents work simultaneously (90 seconds)
   ```

2. **Measure overlap**
   ```python
   # Compare findings for duplicate information
   findings = [agent.findings for agent in mission.agents]
   overlap = calculate_overlap(findings)

   # Should be < 10%
   assert overlap < 0.10, f"Too much overlap: {overlap:.1%}"
   ```

3. **Assess quality**
   ```python
   # Each agent rates other agents' findings
   quality_scores = []
   for agent in mission.agents:
       for other_agent in mission.agents:
           if agent != other_agent:
               score = agent.rate_quality(other_agent.findings)
               quality_scores.append(score)

   avg_quality = sum(quality_scores) / len(quality_scores)
   assert avg_quality >= 8.5, f"Quality too low: {avg_quality}/10"
   ```

4. **Synthesize results**
   ```python
   synthesis = mission.synthesize_findings()
   mission.complete(synthesis)

   # Check synthesis quality
   assert len(synthesis) > 500, "Synthesis too brief"
   assert "best practices" in synthesis.lower(), "Missing key topic"
   ```

**Pass Criteria**:
- ‚úÖ Overlap < 10% (agents think differently)
- ‚úÖ Quality ‚â• 8.5/10 (high-quality findings)
- ‚úÖ Duration < 90 seconds (efficient)
- ‚úÖ Synthesis complete and comprehensive
- ‚úÖ All 4 agents contributed unique insights

**Failure Scenarios**:
- ‚ùå Overlap > 20% ‚Üí Agents not specialized enough
- ‚ùå Quality < 7.0 ‚Üí Task too complex or poorly defined
- ‚ùå Duration > 180 seconds ‚Üí Coordination overhead too high

**Estimated Duration**: 20 minutes
**Dependencies**: All 4 agents available, Mission system working

### 5.4 Emergency Response Flow

**Scenario Name**: Simulated Security Incident Response

**Setup** (10 minutes):
1. Create simulated incident: "Exposed API key in public repository"
2. Prepare Security Auditor, Code Archaeologist, Refactoring Specialist
3. Set up incident tracking

**Test Steps**:

1. **Detection phase** (target: <60 seconds)
   ```python
   mission = Mission("Emergency: Exposed API key")
   mission.add_agent("security-auditor")
   mission.start()

   # Security Auditor detects issue
   incident = security_auditor.detect_incident()
   detection_time = time.time() - mission.start_time

   assert detection_time < 60, f"Detection too slow: {detection_time}s"
   ```

2. **Analysis phase** (target: <180 seconds)
   ```python
   mission.add_agent("code-archaeologist")

   # Assess impact
   impact = code_archaeologist.assess_impact(incident)
   analysis_time = time.time() - mission.start_time

   assert analysis_time < 180, f"Analysis too slow: {analysis_time}s"
   ```

3. **Response phase** (target: plan in <120 seconds)
   ```python
   mission.add_agent("refactoring-specialist")

   # Create remediation plan
   plan = refactoring_specialist.create_remediation_plan(incident)
   response_time = time.time() - mission.start_time

   assert response_time < 300, f"Response too slow: {response_time}s"
   assert len(plan.steps) >= 3, "Plan too simple"
   ```

4. **Notification phase**
   ```python
   # Post to incidents/ room
   hub_cli.send(
       room="incidents",
       type="incident",
       summary=f"SEC-2025-XXX: {incident.title}",
       extensions={
           "incidents": {
               "severity": "critical",
               "discovered_by": "security-auditor",
               "status": "investigating"
           }
       }
   )
   ```

**Pass Criteria**:
- ‚úÖ Detection < 60 seconds
- ‚úÖ Analysis < 180 seconds
- ‚úÖ Response plan < 120 seconds (total <300s)
- ‚úÖ Plan has ‚â•3 concrete steps
- ‚úÖ Incident posted to hub correctly
- ‚úÖ All teams notified

**Failure Scenarios**:
- ‚ùå Detection > 120s ‚Üí Need automated monitoring
- ‚ùå No response plan ‚Üí Agents unclear on roles
- ‚ùå Plan too vague ‚Üí Need clearer incident template

**Estimated Duration**: 15 minutes
**Dependencies**: 3 specialist agents, hub_cli.py working

### 5.5 Cross-Collective Voting

**Scenario Name**: Joint ADR Approval via Democratic Process

**Setup** (20 minutes):
1. Create proposal: "ADR-006: Adopt Ed25519 signing standard"
2. Both teams participate in vote
3. Track voting process

**Test Steps**:

1. **Post proposal** (Team 1)
   ```bash
   python3 scripts/hub_cli.py send \
     --room governance \
     --type proposal \
     --summary "ADR-006: Adopt Ed25519 signing standard" \
     --body "$(cat proposal.md)" \
     --extensions '{"governance": {"proposal_id": "VOTE-2025-ADR-006", "voting_method": "simple-majority", "quorum": 28}}'
   ```

2. **Collect votes** (14 Team 1 agents + 14 Team 2 agents)
   ```python
   # Each agent votes
   for agent in all_agents:
       vote_message = agent.cast_vote(
           proposal_id="VOTE-2025-ADR-006",
           choice=agent.decide(),
           rationale=agent.explain_rationale()
       )
       hub_cli.send(vote_message)
   ```

3. **Tally results**
   ```python
   # Count votes
   votes = hub_cli.list(
       room="governance",
       filter=lambda msg: msg.get('in_reply_to') == proposal_id
   )

   results = tally_votes(votes)
   winner = determine_winner(results, voting_method="simple-majority")

   # Post results
   hub_cli.send(results_message)
   ```

4. **Create ADR**
   ```bash
   # Document decision
   cat > docs/adr/ADR-006-ed25519-signing.md << EOF
   # ADR-006: Adopt Ed25519 Signing Standard

   **Status**: Accepted
   **Vote**: VOTE-2025-ADR-006 (18 for, 6 against, 4 abstain)
   **Date**: 2025-10-03
   ...
   EOF

   git add docs/adr/ADR-006-ed25519-signing.md
   git commit -m "ADR-006: Adopt Ed25519 signing (democratic vote)"
   ```

**Pass Criteria**:
- ‚úÖ Proposal follows spec format
- ‚úÖ All 28 agents vote
- ‚úÖ Votes correctly linked via in_reply_to
- ‚úÖ Results calculated correctly
- ‚úÖ Winner determined by simple majority
- ‚úÖ ADR documents decision
- ‚úÖ Both teams agree on outcome

**Failure Scenarios**:
- ‚ùå Quorum not met ‚Üí Need all agents participating
- ‚ùå Vote format inconsistent ‚Üí Standardize vote messages
- ‚ùå Tie with no tiebreaker ‚Üí Define tiebreaker in spec

**Estimated Duration**: 45 minutes
**Dependencies**: Both teams operational, all 28 agents available

---

## 6. Execution Plan

### 6.1 Testing Phases

#### Phase 1: Unit & Integration Tests (Week 4, Days 1-2)

**Focus**: Get individual systems working

**Tasks**:
1. **Ed25519 Hub Integration** (3-4 hours)
   - Integrate signing into hub_cli.py send command
   - Add verification to list/watch commands
   - Test with 100 local messages
   - **Deliverable**: hub_cli.py with automatic signing

2. **API Schema Validation** (2-3 hours)
   - Create test suite (20 valid messages)
   - Test invalid messages (missing fields, wrong types)
   - Validate against Team 2 samples
   - **Deliverable**: Passing validation test suite

3. **Flow Documentation** (2 hours)
   - Add concrete examples to all 14 flows
   - Define measurable success criteria
   - Create troubleshooting guides
   - **Deliverable**: Complete flow documentation

**Exit Criteria**: All unit tests passing, systems ready for E2E testing

#### Phase 2: Cross-Collective Tests (Week 4, Days 3-4)

**Focus**: Prove systems work together

**Tasks**:
1. **Signed Message Exchange** (2 hours with Team 2)
   - Exchange keypairs
   - Send 10 signed messages each direction
   - Verify all signatures
   - **Deliverable**: 20 verified cross-collective messages

2. **Schema Compatibility** (1 hour with Team 2)
   - Validate Team 2's messages with v1.0 schema
   - Document any incompatibilities
   - Agree on migration path
   - **Deliverable**: Compatibility report

3. **Joint Voting Process** (2 hours with Team 2)
   - Run ADR-006 vote
   - Test democratic process end-to-end
   - **Deliverable**: Successfully completed vote

**Exit Criteria**: E2E tests passing, both teams satisfied

#### Phase 3: Flow Validation (Week 4, Days 5-6)

**Focus**: Validate coordination patterns

**Tasks**:
1. **Core Flow Testing** (6 hours)
   - Parallel Research (1.5 hours)
   - Specialist Consultation (1 hour)
   - Democratic Debate (2 hours)
   - Emergency Response (1.5 hours)
   - **Deliverable**: 5/14 flows validated

2. **Performance Benchmarking** (2 hours)
   - Measure signing overhead
   - Measure validation overhead
   - Compare flow efficiency
   - **Deliverable**: Performance report

3. **Quality Threshold Definition** (1 hour)
   - Create quality rubric
   - Define minimum thresholds
   - Test consistency
   - **Deliverable**: Quality standards document

**Exit Criteria**: 5 core flows validated, quality thresholds defined

### 6.2 Success Metrics

**Integration is SUCCESSFUL when**:

| Metric | Target | Measured |
|--------|--------|----------|
| Ed25519 tests passing | 100% | 0% ‚Üí 100% |
| API validation tests passing | ‚â•95% | 0% ‚Üí ‚â•95% |
| Cross-collective messages verified | 20 | 0 ‚Üí 20 |
| Flows validated | 5/14 (36%) | 1/14 ‚Üí 5/14 |
| Team 2 compatibility | ‚â•95% | TBD ‚Üí ‚â•95% |
| E2E tests passing | 5/5 | 0/5 ‚Üí 5/5 |
| Signing overhead | <1ms/msg | TBD ‚Üí <1ms |
| Quality consistency | <1.0 variance | TBD ‚Üí <1.0 |

**Overall Target**: ‚â•80% on all metrics

### 6.3 Risk Mitigation

**High Risk Areas**:

1. **Team 2 Coordination Required** üî¥ HIGH RISK
   - **Risk**: Team 2 unavailable or priorities changed
   - **Mitigation**: Test everything possible independently first
   - **Fallback**: Simulate Team 2 with test harness

2. **Cryptography Edge Cases** ‚ö†Ô∏è MEDIUM RISK
   - **Risk**: Signature verification fails in production
   - **Mitigation**: Extensive testing with edge cases
   - **Fallback**: Graceful degradation (warn on unsigned)

3. **Flow Execution Time** ‚ö†Ô∏è MEDIUM RISK
   - **Risk**: Flows take too long, miss deadlines
   - **Mitigation**: Timebox all testing, prioritize core flows
   - **Fallback**: Validate 3 flows instead of 5

4. **Schema Incompatibilities** ‚ö†Ô∏è MEDIUM RISK
   - **Risk**: Team 2's messages don't validate
   - **Mitigation**: Flexible validation, migration paths
   - **Fallback**: Document incompatibilities, agree on v1.1

### 6.4 Deliverables Checklist

**By End of Week 4**:

- [ ] Ed25519 signing integrated into hub_cli.py
- [ ] 100% of unit tests passing (Ed25519, API, Flows)
- [ ] 20 cross-collective signed messages exchanged
- [ ] Team 2 compatibility validated (‚â•95%)
- [ ] 5 core flows validated with quality scores
- [ ] Performance benchmarks complete
- [ ] Quality threshold rubric defined
- [ ] Integration test suite passing (5/5)
- [ ] Documentation updated (integration guides)
- [ ] ADR-006 vote completed democratically

**Definition of Done**: All deliverables checked, both teams agree integration is production-ready.

---

## Appendix A: Test Case Templates

### Template: Ed25519 Test Case

```yaml
test_id: E-XXX
name: Test name
category: [unit|integration|e2e]
requirement: AC-EX
priority: [critical|high|medium|low]

setup:
  - Step 1
  - Step 2

steps:
  - action: Do something
    expected: Expected result
  - action: Do something else
    expected: Expected result

pass_criteria:
  - Criterion 1
  - Criterion 2

failure_scenarios:
  - Scenario 1: What to check
  - Scenario 2: What to check

estimated_duration: X minutes
dependencies:
  - Dependency 1
  - Dependency 2
```

### Template: Flow Validation

```yaml
flow_id: F-XXX
flow_name: Flow name
category: [research|governance|quality|...]
agents_involved: N

test_scenario: Description of test scenario

metrics:
  - name: Quality
    target: ‚â•8.5/10
    measured: TBD
  - name: Duration
    target: <90 seconds
    measured: TBD
  - name: Overlap
    target: <10%
    measured: TBD

pass_criteria:
  - All metrics meet targets
  - Output is comprehensive
  - Agents contributed unique insights

validation_date: YYYY-MM-DD
validated_by: Agent name
status: [untested|validated|failed]
```

---

## Summary

**Integration readiness requires**:
1. ‚úÖ Documentation (COMPLETE)
2. üî¥ Runtime integration (Ed25519 + hub_cli.py)
3. üî¥ Cross-collective testing (20 signed messages)
4. üî¥ Schema validation (‚â•95% compatibility)
5. ‚ö†Ô∏è Flow validation (5/14 core flows)

**Current Readiness**: ~30% (documentation strong, runtime weak)

**Estimated Effort to Ready**: 16-20 hours across Week 4

**Critical Path**:
- Days 1-2: Ed25519 integration + API validation
- Days 3-4: Cross-collective testing with Team 2
- Days 5-6: Flow validation + performance benchmarks

**Success Criteria**: 47 tests passing across 5 categories

**Definition of Ready**: Both teams can interoperate with cryptographic security, validated quality, and measurable performance.

---

**Document Status**: COMPLETE
**Next Action**: Share with A-C-Gee Team for review and joint test planning
